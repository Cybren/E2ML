{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statistical Hypothesis Testing II\n",
    "\n",
    "In this notebook, we will implement and apply **statistical hypothesis tests** to make inferences about risks of learning algorithms.\n",
    "\n",
    "At the start, we will compare two learning algorithms on one domain via the paired $t$-test.\n",
    "\n",
    "Subsequently, we will compare the two learning algorithm across multiple domains via the Wilcoxon signed-rank test.\n",
    "\n",
    "### **Table of Contents**\n",
    "1. [Paired $t$-test](#paired-t-test)\n",
    "2. [Wilcoxon Signed-rank Test](#wilcoxon-signed-rank-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Paired $t$-test** <a class=\"anchor\" id=\"paired-t-test\"></a>\n",
    "\n",
    "We implement the function [`t_test_paired`](../e2ml/evaluation/_paired_tests.py) in the [`e2ml.evaluation`](../e2ml/evaluation) subpackage. Once, the implementation has been completed, we check it for varying types of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2ml.evaluation import t_test_paired\n",
    "r_1 = np.round(stats.norm.rvs(loc=0.1, scale=0.03, size=40, random_state=0), 2)\n",
    "r_2 = np.round(stats.norm.rvs(loc=0.12, scale=0.03, size=40, random_state=1), 2)\n",
    "mu_0 = 0\n",
    "t_statistic, p = t_test_paired(sample_data_1=r_1, sample_data_2=r_2, mu_0=mu_0, test_type=\"right-tail\")\n",
    "assert np.round(t_statistic, 4) == -1.4731 , 'The paired t-test statistic must be ca. -1.4731.' \n",
    "assert np.round(p, 4) == 0.9256, 'The p-value must be ca. 0.9256 for the one-sided right-tail test.' \n",
    "t_statistic, p = t_test_paired(sample_data_1=r_1, sample_data_2=r_2, mu_0=mu_0, test_type=\"left-tail\")\n",
    "assert np.round(t_statistic, 4) == -1.4731 , 'The paired t-test statistic must be ca. -1.4731.' \n",
    "assert np.round(p, 4) == 0.0744, 'The p-value must be ca. 0.0744 for the one-sided left-tail test.' \n",
    "t_statistic, p = t_test_paired(sample_data_1=r_1, sample_data_2=r_2, mu_0=mu_0, test_type=\"two-sided\")\n",
    "assert np.round(t_statistic, 4) == -1.4731 , 'The paired t-test statistic must be ca. -1.4731.' \n",
    "assert np.round(p, 4) == 0.1487, 'The p-value must be ca. 0.1487 for the two-sided test.' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to check whether a *support vector classifier* (SVC) significantly outperforms a *Gaussian process classifier* (GPC) on the data set breast cancer, where we use the zero-one loss as performance measure and the paired $t$-test with $\\alpha=0.01$. Design and perform the corresponding evaluation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.305e+01 1.859e+01 8.509e+01 ... 1.258e-01 3.113e-01 8.317e-02]\n",
      " [1.166e+01 1.707e+01 7.370e+01 ... 4.262e-02 2.731e-01 6.825e-02]\n",
      " [8.734e+00 1.684e+01 5.527e+01 ... 0.000e+00 2.445e-01 8.865e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.092e+01 2.509e+01 1.430e+02 ... 2.542e-01 2.929e-01 9.873e-02]\n",
      " [1.729e+01 2.213e+01 1.144e+02 ... 1.528e-01 3.067e-01 7.484e-02]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]]\n",
      "[[1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " [1.426e+01 1.817e+01 9.122e+01 ... 7.530e-02 2.636e-01 7.676e-02]\n",
      " ...\n",
      " [2.321e+01 2.697e+01 1.535e+02 ... 2.593e-01 3.103e-01 8.677e-02]\n",
      " [1.959e+01 1.815e+01 1.307e+02 ... 2.247e-01 3.643e-01 9.223e-02]\n",
      " [2.013e+01 2.825e+01 1.312e+02 ... 1.628e-01 2.572e-01 6.637e-02]]\n",
      "Not enough evidence to reject Null-Hypothesis svc ? gpc\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from e2ml.evaluation import cross_validation, zero_one_loss\n",
    "from e2ml.preprocessing import StandardScaler\n",
    "\n",
    "x, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "sample_idx = np.arange(len(y), dtype=int)\n",
    "n_folds = 8\n",
    "train, test = cross_validation(sample_indices=sample_idx, n_folds=n_folds, y=y, random_state=0)\n",
    "\n",
    "risks_gpc = []\n",
    "risks_svc = []\n",
    "\n",
    "for train_, test_ in zip(train, test):\n",
    "    scaler = StandardScaler().fit(x[train_])\n",
    "    x_train = scaler.transform(x[train_])\n",
    "    x_test = scaler.transform(x[test_])\n",
    "\n",
    "    gpc = GaussianProcessClassifier(random_state=0)\n",
    "    gpc = gpc.fit(x_train, y[train_])\n",
    "    preds_gpc = gpc.predict(x_test)\n",
    "    risks_gpc.append(zero_one_loss(y[test_], preds_gpc))\n",
    "\n",
    "    svc = SVC(random_state=0)\n",
    "    svc = svc.fit(x_train, y[train_])\n",
    "    preds_svc = svc.predict(x_test)\n",
    "    risks_svc.append(zero_one_loss(y[test_], preds_svc))\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "_, p = t_test_paired(risks_gpc, risks_svc, test_type=\"right-tail\")\n",
    "\n",
    "if(p <= alpha):\n",
    "    print(\"Null-Hypothesis can be rejected svc > gpc\")\n",
    "else: \n",
    "    print(\"Not enough evidence to reject Null-Hypothesis svc ? gpc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "1. (a) What are possible issues of your conducted evaluation study?\n",
    "   \n",
    "   zero-one-losses may not be normaly distributed.\n",
    "   \n",
    "   train/test sets may not be independed of each other\n",
    "\n",
    "   Nur ein parameter set evaluiert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Wilcoxon Signed-rank Test** <a class=\"anchor\" id=\"wilcoxon-signed-rank-test\"></a>\n",
    "\n",
    "We implement the function [`wilcoxon_signed_rank_test`](../e2ml/evaluation/_paired_tests.py) in the [`e2ml.evaluation`](../e2ml/evaluation) subpackage. Once, the implementation has been completed, we check it for varying types of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04580879  0.01964259  0.00479271 -0.04941585  0.01993549  0.01027218\n",
      "  0.0738417   0.03170451  0.06266774  0.03020093]\n",
      "47 0.0244140625\n"
     ]
    }
   ],
   "source": [
    "from e2ml.evaluation import wilcoxon_signed_rank_test\n",
    "\n",
    "# Test for exact computation.\n",
    "r_1 = stats.norm.rvs(loc=0.1, scale=0.03, size=10, random_state=0)\n",
    "r_2 = stats.norm.rvs(loc=0.15, scale=0.03, size=10, random_state=1)\n",
    "d = r_2 - r_1\n",
    "print(d)\n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"right-tail\")\n",
    "print(w_statistic, p)\n",
    "assert w_statistic == 47 , 'The positive rank sum statistic must be 47.' \n",
    "assert np.round(p, 4) == 0.0244, 'The p-value must be ca. 0.0244 for the one-sided right-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"left-tail\")\n",
    "assert w_statistic == 47 , 'The positive rank sum statistic must be 47.' \n",
    "assert np.round(p, 4) == 0.9814, 'The p-value must be ca. 0.9814 for the one-sided left-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"two-sided\")\n",
    "assert w_statistic == 47 , 'The positive rank sum statistic must be 47.' \n",
    "assert np.round(p, 4) == 0.0488, 'The p-value must be ca. 0.0488 for the two-sided test.' \n",
    "\n",
    "# Test for approximative computation.\n",
    "r_1 = stats.norm.rvs(loc=2, scale=0.3, size=100, random_state=0)\n",
    "r_2 = stats.norm.rvs(loc=2.1, scale=0.3, size=100, random_state=1)\n",
    "d = r_2 - r_1\n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"right-tail\")\n",
    "assert w_statistic == 3303 , 'The positive rank sum statistic must be 3303.' \n",
    "assert np.round(p, 4) == 0.0037, 'The p-value must be ca. 0.0037 for the one-sided right-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"left-tail\")\n",
    "assert w_statistic == 3303 , 'The positive rank sum statistic must be 3303.' \n",
    "assert np.round(p, 4) == 0.9963, 'The p-value must be ca. 0.9963 for the one-sided left-tail test.' \n",
    "w_statistic, p = wilcoxon_signed_rank_test(sample_data_1=d, test_type=\"two-sided\")\n",
    "assert w_statistic == 3303 , 'The positive rank sum statistic must be 3303.' \n",
    "assert np.round(p, 4) == 0.0075, 'The p-value must be ca. 0.0075 for the two-sided test.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to check whether a *support vector classifier* (SVC) significantly outperforms a *Gaussian process classifier* (GPC) on ten articially generated data sets, where we use the zero-one loss as performance measure and the paired $t$-test with $\\alpha=0.01$. Design and perform the corresponding evaluation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12131799 -2.7757279   0.04820994 ... -1.21374358 -0.71050611\n",
      "   0.57490397]\n",
      " [-1.29519415 -0.97914272  4.61990169 ...  0.005388   -1.46881007\n",
      "  -0.61139575]\n",
      " [ 1.12148302 -1.77725912  1.16641169 ...  4.15128984  2.00781324\n",
      "  -0.95800309]\n",
      " ...\n",
      " [-0.78646999 -2.66726106  2.00719931 ... -1.52853549  1.24404273\n",
      "   0.10399198]\n",
      " [-1.51581074  2.44148393  2.17667149 ... -4.6413538  -1.81543639\n",
      "   0.91340145]\n",
      " [ 1.29976551 -1.27150341 -0.12435306 ... -3.09277562 -1.02787408\n",
      "  -2.19902077]]\n",
      "[[-0.3574577  -0.38860382 -4.02831314 ... -0.11137354 -0.05436675\n",
      "   5.40969274]\n",
      " [-1.51222305  0.58227177 -4.22725733 ... -0.77676272  3.493906\n",
      "   4.60091541]\n",
      " [ 1.51048018 -0.43108294 -1.2149737  ... -0.78605866 -2.1592613\n",
      "   3.55011461]\n",
      " ...\n",
      " [ 1.38677463  1.44079246 -4.0824453  ... -0.04605197  1.31325816\n",
      "   6.32006092]\n",
      " [-1.01477531 -0.68501334 -4.27886272 ...  0.70845974 -0.71924165\n",
      "  -1.85334008]\n",
      " [ 0.85023954 -0.58505412 -2.18147235 ...  0.02513849  0.28350167\n",
      "   0.76551212]]\n",
      "[[ 0.17042548 -0.02304929 -0.74655922 ... -1.67174707 -1.7058572\n",
      "  -6.57803418]\n",
      " [-0.3779905   2.84776123  0.39392775 ...  0.405093    0.54667409\n",
      "  -1.58547741]\n",
      " [ 0.45161034 -1.29665924  0.60282669 ...  1.97686735 -0.0351381\n",
      "   4.91304892]\n",
      " ...\n",
      " [ 0.43741916 -0.62055092 -0.84369562 ... -1.61734436 -0.29050324\n",
      "  -5.05077932]\n",
      " [ 0.97297628  0.53212611  2.0790995  ...  1.09201343 -0.70265549\n",
      "   0.69482943]\n",
      " [-0.86619137 -0.98709816  1.27893148 ... -1.68178797  0.78152332\n",
      "   1.72214438]]\n",
      "[[ 0.47581902 -1.06154688  2.7141939  ...  2.16407746 -0.91135587\n",
      "  -1.11179048]\n",
      " [-2.4134846  -0.1514474  -2.31062195 ... -3.236791    1.09927908\n",
      "   0.77815044]\n",
      " [-0.6262906   0.05815423  3.06690526 ...  1.06942243  0.12194528\n",
      "  -1.27069919]\n",
      " ...\n",
      " [ 1.31471856  0.9975274  -2.18676267 ... -2.67485921 -1.39020706\n",
      "  -3.38196419]\n",
      " [-0.03166577 -0.96624974 -3.24720598 ... -2.04233068  0.28092555\n",
      "  -2.59042858]\n",
      " [ 1.01216724  0.22412224 -3.43288317 ... -2.3138559   0.26286443\n",
      "  -0.36340014]]\n",
      "[[-1.33464443 -1.49462911 -0.55265562 ...  3.77906536 -2.1544241\n",
      "   2.13350457]\n",
      " [ 3.60532493  1.43703671 -0.34706044 ... -4.09574931 -0.04676062\n",
      "   1.55772128]\n",
      " [ 2.96369106 -1.19489261  2.09841477 ... -3.90298279 -0.92628947\n",
      "   1.66730521]\n",
      " ...\n",
      " [-2.35663364 -1.46598825  2.12031427 ... -1.3275546  -3.42258414\n",
      "  -3.89962208]\n",
      " [ 2.23693737 -0.15447447  0.50282887 ... -1.3060405  -0.58277112\n",
      "   1.34208983]\n",
      " [ 5.3170036  -0.95652737  0.87732902 ... -0.59461651  0.71074416\n",
      "  -1.49313961]]\n",
      "[[ -0.68307354  -0.39911753  -0.21500588 ...  -1.9612323   -4.48149914\n",
      "   -3.43809241]\n",
      " [  0.09037945  -2.26686994  -2.3176708  ...  -5.17358165   0.31559057\n",
      "    0.72076122]\n",
      " [  1.04151358 -11.82601068  -0.67880255 ...   0.7499494    0.28724879\n",
      "   -0.3919135 ]\n",
      " ...\n",
      " [ -0.76775487  -3.07132551   1.6649362  ...  -2.05418867  -6.14113391\n",
      "   -0.89359349]\n",
      " [ -0.75101636  -0.81605436  -0.25026506 ...   1.13222715   0.16285775\n",
      "    0.42230828]\n",
      " [ -0.62559648   1.77616213  -1.08913795 ...   0.19354989   3.93624772\n",
      "   -1.83180407]]\n",
      "[[-0.02090842 -0.74472049  2.35808412 ... -0.73991675  0.04677774\n",
      "  -1.82197354]\n",
      " [ 0.6268124  -2.00061001 -2.46049033 ...  2.17321006 -0.58826807\n",
      "   1.23798391]\n",
      " [-1.34657679 -5.17151139 -0.70987622 ... -2.59525542 -1.74356322\n",
      "  -0.78201979]\n",
      " ...\n",
      " [ 1.12147583 -3.58957219  4.36268262 ... -5.28857462 -0.10625007\n",
      "  -2.66609379]\n",
      " [ 0.62896277 -1.7690816  -2.18497939 ... -2.12177985 -1.20777762\n",
      "  -1.2579774 ]\n",
      " [-0.28314763 -4.24782629  3.24466591 ...  0.71084573 -1.85235178\n",
      "   0.03756137]]\n",
      "[[-1.76297267  1.33728639  1.27837986 ... -1.0875689  -3.22331641\n",
      "  -0.98971121]\n",
      " [ 2.56296062  0.06472255 -4.76774828 ... -4.25840217  0.10319485\n",
      "  -0.16913647]\n",
      " [ 0.22903042  0.68890287  6.35353227 ...  3.23456639  3.72203104\n",
      "  -0.09621307]\n",
      " ...\n",
      " [ 1.0015503  -2.2271127   4.21178591 ... -2.6729874  -0.24360957\n",
      "   0.49161279]\n",
      " [-0.40606634  0.65874803 -1.02936705 ...  1.52578827  0.23406013\n",
      "  -0.59745778]\n",
      " [-2.14069968 -0.68781705 -0.92854    ...  0.58530703 -2.03606625\n",
      "   0.17668505]]\n",
      "[[ 3.61381522e+00  6.24845181e+00  4.70712680e+00 ... -2.26715427e-01\n",
      "  -1.88194655e+00  1.17690549e+00]\n",
      " [-1.51969054e+00 -4.32942387e-01 -2.73505315e-03 ...  1.71666824e-01\n",
      "  -6.44078733e-01  6.27686406e-01]\n",
      " [ 6.41096653e+00 -2.32707913e+00 -5.89974488e-01 ... -4.18122283e-01\n",
      "  -2.95331728e-01 -1.90676920e+00]\n",
      " ...\n",
      " [-1.60312943e+00 -1.44457885e+00 -3.75275435e+00 ... -8.22609254e-01\n",
      "  -4.60702007e+00  8.36619099e-01]\n",
      " [-2.62714099e-01 -4.68172280e+00  2.26788101e+00 ...  3.60814777e-01\n",
      "   4.19149080e-01 -2.41015092e-01]\n",
      " [-2.03009713e+00  5.84083360e+00 -6.95146382e+00 ...  9.92934585e-01\n",
      "   8.93789390e-01 -1.25073286e-01]]\n",
      "[[ 2.70655162 -2.90323301  1.93991943 ... -1.45084072  2.04060125\n",
      "  -2.62701143]\n",
      " [-1.2830704   2.41234398  3.62580904 ...  0.51418936  0.2271992\n",
      "   8.02634757]\n",
      " [-2.75285227  3.63627538  1.46649342 ...  0.40861903 -1.071909\n",
      "   2.11138312]\n",
      " ...\n",
      " [-1.09909293  1.33331512 -1.21570747 ... -0.56712012 -0.92130997\n",
      "  -1.9615498 ]\n",
      " [-3.0669264   3.53512004 -4.69865266 ...  0.87310221  0.94500921\n",
      "  -2.05186056]\n",
      " [-3.23572853  1.79073789 -0.62240873 ... -2.9682811   0.30564481\n",
      "  -4.39527957]]\n",
      "0.01171875\n",
      "Not enough evidence to reject Null-Hypothesis svc ? gpc\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create 10 articial data sets.\n",
    "data_sets = []\n",
    "n_classes_list = np.arange(2, 12)\n",
    "for n_classes in n_classes_list:\n",
    "    X, y = make_classification(\n",
    "        n_samples=500, n_classes=n_classes, class_sep=2, n_informative=10, random_state=n_classes\n",
    "    )\n",
    "    data_sets.append((X, y))\n",
    "\n",
    "# TODO\n",
    "sample_idx = np.arange(len(y), dtype=int)\n",
    "n_folds = len(data_sets)\n",
    "train, test = cross_validation(sample_indices=sample_idx, n_folds=n_folds, y=y, random_state=0)\n",
    "\n",
    "risks_gpc = []\n",
    "risks_svc = []\n",
    "\n",
    "for train_, test_, data_set in zip(train, test, data_sets):\n",
    "\n",
    "    x, y = data_set\n",
    "\n",
    "    scaler = StandardScaler().fit(x[train_])\n",
    "    x_train = scaler.transform(x[train_])\n",
    "    x_test = scaler.transform(x[test_])\n",
    "\n",
    "    gpc = GaussianProcessClassifier(random_state=0)\n",
    "    gpc = gpc.fit(x_train, y[train_])\n",
    "    preds_gpc = gpc.predict(x_test)\n",
    "    risks_gpc.append(zero_one_loss(y[test_], preds_gpc))\n",
    "\n",
    "    svc = SVC(random_state=0)\n",
    "    svc = svc.fit(x_train, y[train_])\n",
    "    preds_svc = svc.predict(x_test)\n",
    "    risks_svc.append(zero_one_loss(y[test_], preds_svc))\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "_, p = wilcoxon_signed_rank_test(risks_gpc, risks_svc, test_type=\"right-tail\")\n",
    "print(p)\n",
    "if(p <= alpha):\n",
    "    print(\"Null-Hypothesis can be rejected svc > gpc\")\n",
    "else: \n",
    "    print(\"Not enough evidence to reject Null-Hypothesis svc ? gpc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions:**\n",
    "2. (a) What are possible issues of your conducted evaluation study?\n",
    "   \n",
    "   default values\n",
    "   train overlap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
